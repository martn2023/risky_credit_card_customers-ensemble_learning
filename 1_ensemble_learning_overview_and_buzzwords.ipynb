{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "713398eb-76af-45ec-b5d9-5ad236600524",
   "metadata": {},
   "source": [
    "# I. Overview\n",
    "\n",
    "Pretend that we are are trying to model out investments to understand which stocks to purchase, at what price, and when. In deciding that, we may consider the opionions of different investor advisors. Each investment advisor may:\n",
    "- have educational backgrounds\n",
    "- have a different approach: some look at prices, others look at macro market trends, and some try to calculate company fundamentals\n",
    "- may be stronger suited in different situations: one advisor might be better at consumer goods, another better at the Asian region, another better at new IPOs, and another at large-cap companies with at least 10K employees.\n",
    "\n",
    "\n",
    "### A. Baseline Models\n",
    "The same logic follows with ML and statistic models. Each of these has their own advantages and target use cases. Below are the singleton standalone models we've seen in previous chapters:\n",
    "\n",
    "##### 1. Linear Regression (chapter 2)\n",
    "##### 2. Logistical Regression (chapter 4)\n",
    "##### 3. Decision Tree (chapter 6)\n",
    "\n",
    "### B. Ensemble Learning\n",
    "This is different from baseline models above (relying on \"the best\" advisor alone), in the sense that we involve all the investment advisors at the same time:\n",
    "\n",
    "\n",
    "##### 1. Bagging\n",
    "All investment advisors form an opinion independent of each other, and then we use voting (see next notebook) to leverage the \"wisdom of the crowd\".\n",
    "\n",
    "**Example**: Random Forest - hundreds of Decision Trees running concurrently, but independent of each other. Since I've had limited exposure to that model type, that will be in notebook #4.\n",
    "\n",
    "##### II. Boosting\n",
    "Whereas bagging is concurrent, boosting is sequential.\n",
    "- Advisor A makes his calls\n",
    "- Advisor B looks to see where A's calls missed, and adapts\n",
    "- Advisor C looks to see where B's calls missed, and adapts, and so forth\n",
    "\n",
    "**Examples**: AdaBoost, Gradient Boost, LightGBM\n",
    "\n",
    "##### III. Stacking\n",
    "Stacking is the ML engineer/Data Scientist acting as a team coach who changes the weight of advisor opinions based on the situation.\n",
    "- Step 1: Train different advisors on a data set's values.\n",
    "- Step 2: Find patterns e.g. \"When we see a company in the utilities industry, reduce the weight of Advisor A who keeps getting utility calls wrong and increase the weight of Advisor D who keeps getting those right.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dcde08-61b1-4c95-ae1e-582d90d361bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
